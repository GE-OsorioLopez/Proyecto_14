{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El servicio de venta de autos usados Rusty Bargain está desarrollando una aplicación para atraer nuevos clientes. Gracias a esa app, puedes averiguar rápidamente el valor de mercado de tu coche. Tienes acceso al historial: especificaciones técnicas, versiones de equipamiento y precios. Tienes que crear un modelo que determine el valor de mercado.\n",
    "A Rusty Bargain le interesa:\n",
    "- la calidad de la predicción;\n",
    "- la velocidad de la predicción;\n",
    "- el tiempo requerido para el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulación y análisis de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modelado y Métrica\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a leer los datos de la base de datos usando la librería pandas, una vez importados los datos, procederemos a ver los datos, en que condicion estan, si faltan valores y en que cantidad. Tambien si los tipos de datos corresponden a la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('car_data.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de valores nulos por columna:\n",
      "                   Missing Count  Percentage\n",
      "NotRepaired                71154   20.079070\n",
      "VehicleType                37490   10.579368\n",
      "FuelType                   32895    9.282697\n",
      "Gearbox                    19833    5.596709\n",
      "Model                      19705    5.560588\n",
      "Price                          0    0.000000\n",
      "RegistrationYear               0    0.000000\n",
      "DateCrawled                    0    0.000000\n",
      "Mileage                        0    0.000000\n",
      "Power                          0    0.000000\n",
      "RegistrationMonth              0    0.000000\n",
      "Brand                          0    0.000000\n",
      "DateCreated                    0    0.000000\n",
      "NumberOfPictures               0    0.000000\n",
      "PostalCode                     0    0.000000\n",
      "LastSeen                       0    0.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Conteo de valores nulos por columna:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "missing_info = pd.DataFrame({'Missing Count': missing_data,'Percentage': missing_percentage}).sort_values('Percentage', ascending=False)\n",
    "print(missing_info)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['NotRepaired','VehicleType','FuelType','Gearbox','Model']] = df[['NotRepaired','VehicleType','FuelType','Gearbox','Model']].fillna('unknown')\n",
    "df[['VehicleType','Gearbox','FuelType','NotRepaired']]=df[['VehicleType','Gearbox','FuelType','NotRepaired']].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a comenzar a tratar los valores ausentes. en el caso de \"NotRepaired\" como puede ser si o no, y tenemos este valor pero tiene un alto porcentaje de mi dataset, pondre otro valor como \"unknow\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de valores nulos por columna:\n",
      "                   Missing Count  Percentage\n",
      "DateCrawled                    0         0.0\n",
      "Price                          0         0.0\n",
      "VehicleType                    0         0.0\n",
      "RegistrationYear               0         0.0\n",
      "Gearbox                        0         0.0\n",
      "Power                          0         0.0\n",
      "Model                          0         0.0\n",
      "Mileage                        0         0.0\n",
      "RegistrationMonth              0         0.0\n",
      "FuelType                       0         0.0\n",
      "Brand                          0         0.0\n",
      "NotRepaired                    0         0.0\n",
      "DateCreated                    0         0.0\n",
      "NumberOfPictures               0         0.0\n",
      "PostalCode                     0         0.0\n",
      "LastSeen                       0         0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Conteo de valores nulos por columna:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "missing_info = pd.DataFrame({'Missing Count': missing_data,'Percentage': missing_percentage}).sort_values('Percentage', ascending=False)\n",
    "print(missing_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminamos de ver el tema de valores ausentes , como las columnas eran categoricas por eso se procedio a imputar en todas la palabra \"Unknown\". Ahora procederemos a ver la coherencia de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Price  RegistrationYear          Power        Mileage  \\\n",
      "count  354369.000000     354369.000000  354369.000000  354369.000000   \n",
      "mean     4416.656776       2004.234448     110.094337  128211.172535   \n",
      "std      4514.158514         90.227958     189.850405   37905.341530   \n",
      "min         0.000000       1000.000000       0.000000    5000.000000   \n",
      "25%      1050.000000       1999.000000      69.000000  125000.000000   \n",
      "50%      2700.000000       2003.000000     105.000000  150000.000000   \n",
      "75%      6400.000000       2008.000000     143.000000  150000.000000   \n",
      "max     20000.000000       9999.000000   20000.000000  150000.000000   \n",
      "\n",
      "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
      "count      354369.000000          354369.0  354369.000000  \n",
      "mean            5.714645               0.0   50508.689087  \n",
      "std             3.726421               0.0   25783.096248  \n",
      "min             0.000000               0.0    1067.000000  \n",
      "25%             3.000000               0.0   30165.000000  \n",
      "50%             6.000000               0.0   49413.000000  \n",
      "75%             9.000000               0.0   71083.000000  \n",
      "max            12.000000               0.0   99998.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos varias anomalais en los datos, como que en precio hhubo una venta por 0 euros, en el caso del año del registro hay desde 1000 hasta 9999, en el caso de power hay un valor de 20000 y en el kilometraje hay un valor de 9999999, todos estos valores no son coherentes con la realidad, por lo que se procederá a eliminarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Price  RegistrationYear          Power        Mileage  \\\n",
      "count  340024.000000     354198.000000  313879.000000  354369.000000   \n",
      "mean     4602.471902       2003.084789     122.330895  128211.172535   \n",
      "std      4514.902742          7.536418     106.232815   37905.341530   \n",
      "min       101.000000       1910.000000      10.000000    5000.000000   \n",
      "25%      1200.000000       1999.000000      75.000000  125000.000000   \n",
      "50%      2900.000000       2003.000000     110.000000  150000.000000   \n",
      "75%      6500.000000       2008.000000     150.000000  150000.000000   \n",
      "max     20000.000000       2019.000000    9710.000000  150000.000000   \n",
      "\n",
      "       RegistrationMonth  NumberOfPictures     PostalCode  \n",
      "count      354369.000000          354369.0  354369.000000  \n",
      "mean            5.714645               0.0   50508.689087  \n",
      "std             3.726421               0.0   25783.096248  \n",
      "min             0.000000               0.0    1067.000000  \n",
      "25%             3.000000               0.0   30165.000000  \n",
      "50%             6.000000               0.0   49413.000000  \n",
      "75%             9.000000               0.0   71083.000000  \n",
      "max            12.000000               0.0   99998.000000  \n"
     ]
    }
   ],
   "source": [
    "df['Price']=df['Price'].drop(df[df['Price']<=100].index)\n",
    "df['Power']=df['Power'].drop(df[(df['Power']>=10000) | (df['Power']<10)].index)\n",
    "df['RegistrationYear']=df['RegistrationYear'].drop(df[(df['RegistrationYear']<1900) | (df['RegistrationYear']>2025)].index)\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo tenemos el df limpio y listo para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelo de Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oslo_\\AppData\\Local\\Temp\\ipykernel_23684\\217730971.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "C:\\Users\\oslo_\\AppData\\Local\\Temp\\ipykernel_23684\\217730971.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "C:\\Users\\oslo_\\AppData\\Local\\Temp\\ipykernel_23684\\217730971.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
      "C:\\Users\\oslo_\\AppData\\Local\\Temp\\ipykernel_23684\\217730971.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Preparación de datos completada sin errores!\n",
      "Total de nulos en y_train_ohe: 0\n"
     ]
    }
   ],
   "source": [
    "# --- INICIA EL BLOQUE DE CÓDIGO MÁS ROBUSTO ---\n",
    "\n",
    "# Carga tus datos (si no lo has hecho)\n",
    "# df = pd.read_csv('tu_archivo.csv', encoding='ISO-8859-1') \n",
    "\n",
    "# 1. FORZAR LA COLUMNA 'Price' A SER NUMÉRICA (NUEVO PASO CRÍTICO)\n",
    "# El parámetro errors='coerce' convertirá cualquier valor que no sea un número en NaN.\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')\n",
    "\n",
    "# 2. AHORA SÍ, ELIMINAR TODAS LAS FILAS DONDE 'Price' SEA NULO\n",
    "# Esto eliminará tanto los nulos originales como los que acabamos de crear en el paso anterior.\n",
    "df.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "# 3. Limpieza de columnas y anomalías (el resto del código que ya conoces)\n",
    "df_cleaned = df.drop(columns=['DateCrawled', 'DateCreated', 'LastSeen', 'PostalCode', 'NumberOfPictures', 'RegistrationMonth'])\n",
    "current_year = datetime.now().year\n",
    "df_cleaned = df_cleaned[(df_cleaned['RegistrationYear'] >= 1950) & (df_cleaned['RegistrationYear'] <= current_year)]\n",
    "df_cleaned = df_cleaned[(df_cleaned['Power'] >= 50) & (df_cleaned['Power'] <= 1000)]\n",
    "df_cleaned['CarAge'] = current_year - df_cleaned['RegistrationYear']\n",
    "df_cleaned = df_cleaned.drop(columns=['RegistrationYear'])\n",
    "\n",
    "# 4. Rellenar nulos restantes en las CARACTERÍSTICAS (X)\n",
    "numerical_cols = df_cleaned.select_dtypes(include=np.number).columns.drop('Price')\n",
    "categorical_cols = df_cleaned.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df_cleaned[col].fillna(df_cleaned[col].median(), inplace=True)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)\n",
    "\n",
    "# 5. Codificación y División de Datos\n",
    "df_final = df_cleaned.copy()\n",
    "categorical_features = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'Brand', 'NotRepaired']\n",
    "for col in categorical_features:\n",
    "    df_final[col] = df_final[col].astype('category')\n",
    "\n",
    "df_ohe = pd.get_dummies(df_final, columns=categorical_features, drop_first=True)\n",
    "\n",
    "X_cat = df_final.drop('Price', axis=1)\n",
    "y = df_final['Price']\n",
    "X_ohe = df_ohe.drop('Price', axis=1)\n",
    "\n",
    "X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_cat, y, test_size=0.2, random_state=42)\n",
    "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(X_ohe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"¡Preparación de datos completada sin errores!\")\n",
    "print(\"Total de nulos en y_train_ohe:\", y_train_ohe.isnull().sum())\n",
    "\n",
    "# --- FIN DEL BLOQUE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento (categorical): (239623, 9)\n",
      "Tamaño del conjunto de prueba (categorical): (59906, 9)\n",
      "Tamaño del conjunto de entrenamiento (ohe): (239623, 310)\n",
      "Tamaño del conjunto de prueba (ohe): (59906, 310)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño del conjunto de entrenamiento (categorical): {X_train_cat.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba (categorical): {X_test_cat.shape}\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento (ohe): {X_train_ohe.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba (ohe): {X_test_ohe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                      0\n",
      "Power                      0\n",
      "Mileage                    0\n",
      "CarAge                     0\n",
      "VehicleType_convertible    0\n",
      "                          ..\n",
      "Brand_trabant              0\n",
      "Brand_volkswagen           0\n",
      "Brand_volvo                0\n",
      "NotRepaired_unknown        0\n",
      "NotRepaired_yes            0\n",
      "Length: 311, dtype: int64\n",
      "Power                      0\n",
      "Mileage                    0\n",
      "CarAge                     0\n",
      "VehicleType_convertible    0\n",
      "VehicleType_coupe          0\n",
      "                          ..\n",
      "Brand_trabant              0\n",
      "Brand_volkswagen           0\n",
      "Brand_volvo                0\n",
      "NotRepaired_unknown        0\n",
      "NotRepaired_yes            0\n",
      "Length: 310, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_ohe.isnull().sum())\n",
    "print(X_train_ohe.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1: Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE de Regresión Lineal: 2557.41 euros\n",
      "CPU times: total: 30.2 s\n",
      "Wall time: 5.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_ohe, y_train_ohe)\n",
    "\n",
    "y_pred_linear = lr.predict(X_test_ohe)\n",
    "\n",
    "rmse_linear = np.sqrt(mean_squared_error(y_test_ohe, y_pred_linear))\n",
    "print(f\"RMSE de Regresión Lineal: {rmse_linear:.2f} euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2: Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo Random Forest...\n",
      "Entrenamiento completado.\n",
      "\n",
      "RMSE de Random Forest: 1572.58 euros\n",
      "CPU times: total: 22min 42s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = RandomForestRegressor(n_estimators=100,max_depth=20, random_state=123, n_jobs=-1)\n",
    "\n",
    "# 2. Entrenar el modelo con los datos OHE\n",
    "print(\"Entrenando el modelo Random Forest...\")\n",
    "rf_model.fit(X_train_ohe, y_train_ohe)\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "# 3. Hacer predicciones y evaluar\n",
    "y_pred_rf = rf_model.predict(X_test_ohe)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_ohe, y_pred_rf))\n",
    "\n",
    "print(f\"\\nRMSE de Random Forest: {rmse_rf:.2f} euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo Random Forest...\n",
      "Entrenamiento completado.\n",
      "RMSE de Decision Tree: 1977.94 euros\n",
      "CPU times: total: 4.5 s\n",
      "Wall time: 4.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt_model = DecisionTreeRegressor(max_depth=10, random_state=123)\n",
    "print(\"Entrenando el modelo Random Forest...\")\n",
    "dt_model.fit(X_train_ohe, y_train_ohe)\n",
    "print(\"Entrenamiento completado.\")\n",
    "y_pred_dt = dt_model.predict(X_test_ohe)\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test_ohe, y_pred_dt))\n",
    "print(f\"RMSE de Decision Tree: {rmse_dt:.2f} euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 4: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 239623, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 4897.793284\n",
      "RMSE de LightGBM (default): 1608.73 euros\n",
      "CPU times: total: 5.08 s\n",
      "Wall time: 946 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_model = lgb.LGBMRegressor(random_state=42)\n",
    "lgbm_model.fit(X_train_cat, y_train)\n",
    "\n",
    "y_pred_lgbm = lgbm_model.predict(X_test_cat)\n",
    "rmse_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "\n",
    "print(f\"RMSE de LightGBM (default): {rmse_lgbm:.2f} euros\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 5: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE de CatBoost (default): 1585.09 euros\n",
      "CPU times: total: 16min 50s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_features_names = X_train_cat.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "# Inicializar y entrenar el modelo\n",
    "cat_model = CatBoostRegressor(random_state=42, verbose=0, cat_features=cat_features_names)\n",
    "cat_model.fit(X_train_cat, y_train)\n",
    "y_pred_cat = cat_model.predict(X_test_cat)\n",
    "rmse_cat = np.sqrt(mean_squared_error(y_test, y_pred_cat))\n",
    "\n",
    "print(f\"RMSE de CatBoost (default): {rmse_cat:.2f} euros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
